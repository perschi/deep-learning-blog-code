{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data/', train=True,  download=False, transform=transforms)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, drop_last=True, batch_size=2, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data/', train=False,  download=False, transform=transforms)\n",
    "test_loader = torch.utils.data.DataLoader(trainset, drop_last=True, batch_size=2, shuffle=False)\n",
    "\n",
    "class ReshapeLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, shape):\n",
    "        super(ReshapeLayer, self).__init__()\n",
    "        self.shape = shape\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.reshape(self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_size = 10\n",
    "\n",
    "    \n",
    "transform = nn.Sequential(\n",
    "                        nn.Conv2d(1, 64, 5), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                        nn.Conv2d(64,64, 5), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                        nn.Conv2d(64,64, 5), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                        nn.Conv2d(64,64, 5), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                        nn.Flatten(), nn.Linear(64 * (28 - 4*4)**2, latent_space_size),\n",
    "                        nn.Linear(latent_space_size, 64 * (28 - 4*4)**2), nn.ReLU(), ReshapeLayer([-1, 64,(28 - 4*4),(28 - 4*4)]),\n",
    "                        nn.ConvTranspose2d(64,64,5), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                        nn.ConvTranspose2d(64,64,5), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                        nn.ConvTranspose2d(64,64,5), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                        nn.ConvTranspose2d(64, 1,5)).to(device)\n",
    "\n",
    "\n",
    "optim = torch.optim.Adam(transform.parameters())\n",
    "\n",
    "for epoch in range(2):\n",
    "    for it, (x, _) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        prediction = transform(x)\n",
    "        loss = F.mse_loss(prediction,torch.flip(x, dims=[0]))\n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        if not it % 100:\n",
    "            print(loss)\n",
    "         \n",
    "        if not it % 1000:\n",
    "            fig, axis = plt.subplots(ncols=4)\n",
    "            axis[0].imshow(x[0,0].detach().cpu().numpy())\n",
    "            axis[0].set_title('input 1')\n",
    "            axis[1].imshow(prediction[0,0].detach().cpu().numpy())\n",
    "            axis[1].set_title('transformed 1')\n",
    "            axis[2].imshow(x[1,0].detach().cpu().numpy())\n",
    "            axis[2].set_title('input 2')\n",
    "            axis[3].imshow(prediction[1,0].detach().cpu().numpy())\n",
    "            axis[3].set_title('transformed 2')\n",
    "\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for it, (x, _) in enumerate(train_loader):\n",
    "    transform.train(True)\n",
    "\n",
    "    x = x.to(device)\n",
    "    train_prediction = transform(x)[:,0].detach().cpu().numpy()\n",
    "\n",
    "    transform.train(False)\n",
    "    test_prediction = transform(x)[:,0].detach().cpu().numpy()\n",
    "    \n",
    "    x = x.detach().cpu().numpy()[:,0]\n",
    "    \n",
    "    fig, axis = plt.subplots(nrows=2, ncols=3, figsize=(10,5))\n",
    "    axis[0,0].imshow(x[0])\n",
    "    axis[0,0].set_xticks(ticks=[])\n",
    "    axis[0,0].set_yticks(ticks=[])\n",
    "    axis[0,0].set_ylabel('Element 1')\n",
    "    axis[0,0].set_title('Input')\n",
    "\n",
    "    \n",
    "    axis[0,1].imshow(train_prediction[0])\n",
    "    axis[0,1].set_xticks(ticks=[])\n",
    "    axis[0,1].set_yticks(ticks=[])\n",
    "    axis[0,1].set_title('Reconstruction in training mode')\n",
    "\n",
    "    \n",
    "    axis[1,0].imshow(x[1])\n",
    "    axis[1,0].set_xticks(ticks=[])\n",
    "    axis[1,0].set_yticks(ticks=[])\n",
    "    axis[1,0].set_ylabel('Element 2')\n",
    "\n",
    "    \n",
    "    axis[1,1].imshow(train_prediction[1])\n",
    "    axis[1,1].set_xticks(ticks=[])\n",
    "    axis[1,1].set_yticks(ticks=[])\n",
    "    \n",
    "    axis[0,2].imshow(test_prediction[0])\n",
    "    axis[0,2].set_xticks(ticks=[])\n",
    "    axis[0,2].set_yticks(ticks=[])\n",
    "    axis[0,2].set_title('Reconstruction in test mode')\n",
    "    \n",
    "    axis[1,2].imshow(test_prediction[1])\n",
    "    axis[1,2].set_xticks(ticks=[])\n",
    "    axis[1,2].set_yticks(ticks=[])\n",
    "\n",
    "    plt.savefig('example'+str(it)+'.svg', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    if it == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 0\n",
    "sum_train_losses = 0.0\n",
    "sum_test_losses = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for it, (x, _) in enumerate(test_loader):\n",
    "        transform.train(True)\n",
    "\n",
    "        x = x.to(device)\n",
    "        train_prediction = transform(x)\n",
    "\n",
    "        transform.train(False)\n",
    "        test_prediction = transform(x)\n",
    "\n",
    "        batches +=1\n",
    "        \n",
    "        sum_train_losses += F.mse_loss(train_prediction, torch.flip(x, dims=[0])).detach().cpu().numpy()\n",
    "        sum_test_losses += F.mse_loss(test_prediction, torch.flip(x, dims=[0])).detach().cpu().numpy()\n",
    "        \n",
    "        if not it % 100\n",
    "        \n",
    "print('Train', sum_train_losses/batches , 'test', sum_test_losses / batches)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 4*np.pi, 100)\n",
    "fx = np.sin(x) + 2 * np.cos(0.5*x)\n",
    "\n",
    "plt.plot(x, fx)\n",
    "plt.savefig('function.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SimpleContrast(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, resolution, sequence_length):\n",
    "        \n",
    "        x = np.linspace(0, 4*np.pi, resolution)\n",
    "        self.data = np.sin(x) + 2 * np.cos(0.5*x)\n",
    "        \n",
    "\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self._len = resolution // sequence_length -1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.sequence_length\n",
    "        \n",
    "        input_length = self.sequence_length - 1\n",
    "        elements = []\n",
    "        targets = []\n",
    "        for i in range(self.batch_size-1):\n",
    "            elements.append(self.data[start+i:start+i + input_length])\n",
    "            targets.append(self.data[start+i + input_length])\n",
    "            \n",
    "        return torch.from_numpy(np.stack(elements, axis=0)[:,None,:]).type(torch.float32), torch.tensor(targets).type(torch.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "steps= 1000.0\n",
    "for sequence_length in range(4,21):\n",
    "    ds = SimpleContrast(1000, sequence_length)\n",
    "    for batch_size in range(1,7):\n",
    "        print(sequence_length, batch_size)\n",
    "        print('Training')\n",
    "        train_loader = torch.utils.data.DataLoader(ds, drop_last=True, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        model = nn.Sequential(\n",
    "            nn.Conv1d(1 , 32, 3, 1, 1), nn.BatchNorm1d(32), nn.ReLU(),\n",
    "            nn.Conv1d(32, 32, 3, 1, 1), nn.BatchNorm1d(32), nn.ReLU(),\n",
    "            nn.Conv1d(32, 32, 3, 1, 1), nn.BatchNorm1d(32), nn.ReLU(),\n",
    "            nn.Conv1d(32, 32, 3, 1, 1), nn.BatchNorm1d(32), nn.ReLU(),\n",
    "            nn.Conv1d(32, 32, 3, 1, 1), nn.BatchNorm1d(32), nn.ReLU(),\n",
    "            nn.Conv1d(32, 32, 3, 1, 1), nn.BatchNorm1d(32), nn.ReLU(),\n",
    "            nn.Conv1d(32, 1, sequence_length - 1), nn.Flatten()).to(device)\n",
    "\n",
    "        optim = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "        for epoch in range(int((steps/(len(ds)/batch_size)) + 0.9999)):\n",
    "            for it, (x,y) in enumerate(train_loader):\n",
    "                x = x.reshape([-1, 1, sequence_length - 1]).to(device)\n",
    "                y = y.reshape([-1, 1]).to(device)\n",
    "\n",
    "                loss = F.mse_loss(model(x),y)\n",
    "                loss.backward()\n",
    "\n",
    "                optim.step()\n",
    "                optim.zero_grad()\n",
    "                \n",
    "                \n",
    "        test_loader = torch.utils.data.DataLoader(ds, drop_last=True, batch_size=1, shuffle=False)\n",
    "        \n",
    "        sum_train_loss = 0.0\n",
    "        sum_test_loss = 0.0\n",
    "\n",
    "        batches = 0.0\n",
    "        \n",
    "        print('testing')\n",
    "        for it, (x,y) in enumerate(train_loader):\n",
    "\n",
    "            x = x.reshape([-1, 1, sequence_length - 1]).to(device)\n",
    "            y = y.reshape([-1, 1]).to(device)\n",
    "\n",
    "            model.train(True)\n",
    "            sum_train_loss += F.mse_loss(model(x),y).detach().cpu().numpy()\n",
    "\n",
    "            model.train(False)\n",
    "            sum_test_loss += F.mse_loss(model(x),y).detach().cpu().numpy()\n",
    "\n",
    "            batches += 1\n",
    "\n",
    "        results.append((sequence_length, batch_size, sum_train_loss/ batches, sum_test_loss/batches))\n",
    "        print(results[-1])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a_cheat = [t[2] for t in results if t[2] <  t[3]]\n",
    "b_cheat = [t[3] for t in results if t[2] < t[3]]\n",
    "\n",
    "\n",
    "a_fair = [t[2] for t in results if t[2] >= t[3]]\n",
    "b_fair = [t[3] for t in results if t[2] >= t[3]]\n",
    "\n",
    "plt.scatter(a_cheat,b_cheat, label='cheating')\n",
    "plt.scatter(a_fair, b_fair, label='fair')\n",
    "plt.plot([0, 2], [0,2])\n",
    "plt.ylim([0,1])\n",
    "plt.xlim([0,1])\n",
    "plt.ylabel('test mode performance')\n",
    "plt.xlabel('train mode performance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_cheat = [t[0] for t in results if t[2] < t[3]]\n",
    "batch_size_cheat = [t[1] for t in results if t[2] < t[3]]\n",
    "\n",
    "\n",
    "lengths_fair = [t[0] for t in results if t[2] >= t[3]]\n",
    "batch_size_fair = [t[1] for t in results if t[2] >= t[3]]\n",
    "\n",
    "\n",
    "plt.scatter(lengths_cheat, batch_size_cheat, label='cheat')\n",
    "plt.scatter(lengths_fair, batch_size_fair, label='fair')\n",
    "plt.plot([3.5,20.5], [1,6], color='black')\n",
    "plt.legend()\n",
    "plt.ylabel('batch_size')\n",
    "plt.xlabel('sequence length')\n",
    "plt.savefig('cheatfair.svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
